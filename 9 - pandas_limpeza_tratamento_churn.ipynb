{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ly1-WGXaP33O"
   },
   "source": [
    "# Conhecendo os dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1sec6ZTujeju",
    "outputId": "e22b81bb-5cd9-42f0-9703-c50b74e96a8e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'pandas-dados/dataset-telecon.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_churn = pd.read_json(url)\n",
    "dados_churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_churn[0:1].to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_churn.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(dados_churn['conta']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(dados_churn['telefone']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvUxQeHvUXYh"
   },
   "source": [
    "## Transformando dados em uma tabela\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pude perceber que utilizar o json_normalize() para todas colunas é mais trabalho, portanto, deve existir um jeito mais facil de normalizar o JSON de um vez só, sem a necessidade de fazer a normalizacao uma para cada coluna.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(url) as f:\n",
    "    json_bruto = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_bruto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_normalizados = pd.json_normalize(json_bruto)\n",
    "dados_normalizados.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_normalizados.iloc[0].to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformação inicial dos dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entendendo os dados\n",
    "\n",
    "A base de dados contém colunas além do ID dos clientes e o churn:\n",
    "\n",
    "**Cliente:**\n",
    "\n",
    "- `genero:` gênero (masculino e feminino)\n",
    "- `idoso:` informação sobre um cliente ter ou não idade igual ou maior que 65 anos\n",
    "- `parceiro:` se o cliente possui ou não um parceiro ou parceira\n",
    "- `dependentes:` se o cliente possui ou não dependentes\n",
    "- `tempo_servico:` meses de contrato do cliente\n",
    "\n",
    "**Serviço de telefonia**\n",
    "\n",
    "- `servico_telefone:` assinatura de serviço telefônico\n",
    "- `varias_linhas:` assinatura de mais de uma linha de telefone\n",
    "\n",
    "**Serviço de internet**\n",
    "\n",
    "- `servico_internet:` assinatura de um provedor internet\n",
    "- `seguranca_online:` assinatura adicional de segurança online\n",
    "- `backup_online:` assinatura adicional de backup online\n",
    "- `protecao_dispositivo:` assinatura adicional de proteção no dispositivo\n",
    "- `suporte_tecnico:` assinatura adicional de suporte técnico, menos tempo de espera\n",
    "- `tv_streaming:` assinatura de TV a cabo\n",
    "- `filmes_streaming:` assinatura de streaming de filmes\n",
    "\n",
    "**Conta**\n",
    "\n",
    "- `contrato:` tipo de contrato\n",
    "- `faturamente_eletronico:` se o cliente prefere receber online a fatura\n",
    "- `metodo_pagamento:` forma de pagamento\n",
    "- `cobranca.mensal:` total de todos os serviços do cliente por mês\n",
    "- `cobranca.Total:` total gasto pelo cliente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_normalizados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificando o tipo de coluna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_normalizados[dados_normalizados['conta.cobranca.Total'] == ' '].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_normalizados[dados_normalizados['conta.cobranca.Total'] == ' '][['cliente.tempo_servico','conta.contrato', 'conta.cobranca.mensal', 'conta.cobranca.Total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = dados_normalizados[dados_normalizados['conta.cobranca.Total'] == ' '].index\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_normalizados.loc[idx, 'conta.cobranca.Total'] = dados_normalizados.loc[idx, 'conta.cobranca.mensal'] * 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_normalizados.loc[idx, 'cliente.tempo_servico'] = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_normalizados.loc[idx][['cliente.tempo_servico','conta.contrato', 'conta.cobranca.mensal', 'conta.cobranca.Total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_normalizados['conta.cobranca.Total'] = dados_normalizados['conta.cobranca.Total'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_normalizados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vamos visualizar os valores unicos de cada coluna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in dados_normalizados.columns:\n",
    "    print(f'Coluna: {col}')\n",
    "    print(dados_normalizados[col].unique())\n",
    "    print('-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifiquei que na coluna Churn tem um ' ' que nao diz respeito e nao ajuda em analise alguam, portanto, vamos tratar isso\n",
    "dados_normalizados.query(\"Churn == ''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos descartar essas informacoes de cima porque nao faz sentido ficarem em branco\n",
    "\n",
    "dados_sem_vazio = dados_normalizados[dados_normalizados['Churn'] != ''].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_sem_vazio.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como podemos perceber temos index faltantes e precisamos ajustar isso (Index: 7118 entries, 0 to 7343), pois em um modelo de machine learning ele espera que vamos ter indexes consecutivos\n",
    "# drop = True vai retirar a coluna index que ele iria adicionar, o inplace já altera automaticamente sem precisar referenciar.\n",
    "dados_sem_vazio.reset_index(drop=True, inplace=True)\n",
    "dados_sem_vazio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabalhando com dadso duplicados e nulos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificando e tratando dados duplicados\n",
    "\n",
    "dados duplicados ==> possuem os mesmos valores em colunas correspondentes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o metodo duplicated retorna uma series booleana. false para quando a amostra nao é duplicada, e True para quando a amostra é duplicada\n",
    "dados_sem_vazio.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_sem_vazio.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro_duplicadas = dados_sem_vazio.duplicated()\n",
    "filtro_duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_sem_vazio[filtro_duplicadas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, para essas amostras duplicadas, vamos precisar remove-las do conjunto, pois:\n",
    "\n",
    "- Vies do modelo: pode ser que o modelo dë mais importancia para essas amostras que sao duplicadas\n",
    "- Melhora do desempenho do modelo: se inserimos amostra que sao duplicadas, estaremos desperdicando poder computacional, para processar com amostras que transmitem o mesmo valor\n",
    "- Aumento da qualidade dos resultados: isso porque estaremos utilizando informacoes que transmitem mais qualidade por serem unicas e relevantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_sem_vazio.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_sem_vazio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_sem_vazio.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificando e tratando dados nulos\n",
    "\n",
    "dados nulos ==> valores ausentes ou desconhecidos na base de dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se o valor for False é porque nao é nulo\n",
    "# se o valor do True é porque o valor é nulo\n",
    "dados_sem_vazio.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# da forma anterior é ruim de verificar a quantidade de informacoes nulas e portanto conseguimos usar o codigo abaixo para verificar onde temos dados nulos\n",
    "dados_sem_vazio.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_sem_vazio.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos fazer um filtro para entender quantas amostras temos nulas\n",
    "# o axis = 1 faz referencia a coluna\n",
    "dados_sem_vazio[dados_sem_vazio.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_sem_vazio['cliente.tempo_servico'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisando as colunas que temos dados nulos, podemos ajustar a tempo_servico porque ela possui uma relacao com as demais\n",
    "filtro = dados_sem_vazio['cliente.tempo_servico'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_sem_vazio[filtro][['cliente.tempo_servico','conta.cobranca.mensal','conta.cobranca.Total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_vazio = dados_sem_vazio[filtro].index\n",
    "idx_vazio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_sem_vazio.loc[idx_vazio, 'cliente.tempo_servico'] = np.ceil(dados_sem_vazio.loc[idx_vazio, 'conta.cobranca.Total'] / dados_sem_vazio.loc[idx_vazio, 'conta.cobranca.mensal'])\n",
    "dados_sem_vazio[filtro][['cliente.tempo_servico','conta.cobranca.mensal','conta.cobranca.Total']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### poderiamos utilizar essa segunda abortagem tambem para fazer essa conta anterior\n",
    "\n",
    "```python\n",
    "dados_sem_vazio['cliente.tempo_servico'].fillna(\n",
    "    np.ceil(\n",
    "        dados_sem_vazio['conta.cobranca.Total'] / dados_sem_vazio['conta.cobranca.mensal']\n",
    "    ), inplace= True\n",
    ")\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_sem_vazio.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "podemos perceber que todas que ainda tem valores nulos, vem da chave conta. Será que podemos realizar algum tipo de inserção igual fizemos anteriormente?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_sem_vazio['conta.contrato'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jã que nao tenho como inferir algo para substituir os valores, vamos retirar essas informacoes\n",
    "\n",
    "colunas_dropar = ['conta.contrato', 'conta.faturamente_eletronico', 'conta.metodo_pagamento']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_sem_vazio[colunas_dropar].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_sem_vazio[colunas_dropar].isna().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_sem_vazio[colunas_dropar].isna().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# portanto temos 37 amostras que tem pelo menos um valor nulo nessas tres colunas\n",
    "\n",
    "df_sem_nulo = dados_sem_vazio.dropna(subset=colunas_dropar).copy()\n",
    "df_sem_nulo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos reiniciar o indeces porque nao esta iniciando em zero\n",
    "\n",
    "df_sem_nulo.reset_index(drop = True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_nulo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_nulo.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para saber mais: inserindo a moda nos dados\n",
    "\n",
    "A imputação de valores nulos em um Pandas DataFrame é uma das técnicas úteis quando se trabalha com dados faltantes. A imputação é o processo de substituir os valores faltantes por outros valores, de modo a tornar o conjunto de dados mais completo e utilizável.\n",
    "\n",
    "A moda é uma medida estatística que representa o valor mais frequente em um conjunto de dados. Utilizá-la para preencher valores nulos é uma técnica simples e eficaz que pode ajudar a melhorar a qualidade dos dados.\n",
    "\n",
    "Imagine que você esteja trabalhando com um conjunto de dados que contém informações sobre vendas em uma loja. Algumas dessas informações podem estar faltando, como o tamanho de alguns produtos. Nesse caso, você pode usar a moda para preencher os valores nulos. Isso significa que você irá substituir os valores faltantes pelo tamanho mais comum dos produtos.\n",
    "\n",
    "Para fazer isso no Pandas, você pode seguir conforme código abaixo:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Criando um DataFrame de exemplo\n",
    "\n",
    "df = pd.DataFrame({'Produto': ['Camisa', 'Calça', 'Tênis', 'Meia', 'Boné'],\n",
    "                   'Tamanho': ['P', 'M', 'M', None, None],\n",
    "                   'Preço': [49.99, 79.99, 199.99, 9.99, 39.99]})\n",
    "\n",
    "# Preenchendo os valores nulos com a moda\n",
    "\n",
    "df['Tamanho'].fillna(df['Tamanho'].mode()[0], inplace=True)\n",
    "print(df)\n",
    "```\n",
    "\n",
    "Nesse exemplo, o DataFrame possui valores nulos na coluna \"Tamanho\". Para preencher esses valores com a moda, utilizamos o método \"fillna()\" em conjunto com o método \"mode()\". Esta retorna o valor mais comum em um conjunto de dados.\n",
    "\n",
    "No caso do DataFrame acima, a moda da coluna \"Tamanho\" é \"M\". Portanto, utilizamos esse valor para preencher os valores nulos na respectiva coluna. O resultado final é um DataFrame mais completo e utilizável, pronto para ser analisado e usado em futuras análises e decisões de negócios.\n",
    "\n",
    "Ao executar o código acima, o resultado será o seguinte DataFrame:\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th></th>\n",
    "            <th>Produto</th>\n",
    "            <th>Tamanho</th>\n",
    "            <th>Preço</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>0</td>\n",
    "            <td>Camisa</td>\n",
    "            <td>P</td>\n",
    "            <td>49.99</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>1</td>\n",
    "            <td>Calça</td>\n",
    "            <td>M</td>\n",
    "            <td>79.99</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>2</td>\n",
    "            <td>Tênis</td>\n",
    "            <td>M</td>\n",
    "            <td>199.99</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>3</td>\n",
    "            <td>Meia</td>\n",
    "            <td>M</td>\n",
    "            <td>9.99</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>4</td>\n",
    "            <td>Boné</td>\n",
    "            <td>M</td>\n",
    "            <td>39.99</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "Observe que os valores nulos foram substituídos pela moda.\n",
    "\n",
    "Para conferir com mais detalhes os métodos utilizados, você pode consultar suas documentações oficiais:\n",
    "\n",
    "- [método mode](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html)\n",
    "- [método fillna](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabalhando com os outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier\n",
    "\n",
    "- Valor atipico ou ponto fora da curva\n",
    "- Dado que difere do padrao do conjunto de dados significativamente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identificando os outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_nulo.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iremos utilizar o blox plot para entender se temos algum outlier na coluna de tempo_servico, porque 1080 meses sao 90 anos e é muito dificil alguem assinar por tanto tempo. \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df_sem_nulo['cliente.tempo_servico'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pela figura anterior, podemos perceber que temos 10 itens que sao outliers, logo temos que tentar identificar quais sao\n",
    "Q1 = df_sem_nulo['cliente.tempo_servico'].quantile(.25)\n",
    "Q3 = df_sem_nulo['cliente.tempo_servico'].quantile(.75)\n",
    "IQR = Q3 - Q1\n",
    "limite_inferior = Q1 - 1.5*IQR\n",
    "limite_superior = Q3 + 1.5*IQR\n",
    "print(f'Q1: {Q1}\\nQ3: {Q3}\\nIQR: {IQR}\\nlimite_inferior: {limite_inferior}\\nlimite_superior: {limite_superior}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# portanto, com isso conseguimos aplicar o filtro de valores menores que o limite inferior ou maiores que o limite superior\n",
    "\n",
    "outliers_index = (df_sem_nulo['cliente.tempo_servico'] < limite_inferior) | (df_sem_nulo['cliente.tempo_servico'] > limite_superior)\n",
    "outliers_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_nulo[outliers_index]['cliente.tempo_servico']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Substituindo valores para os Outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_out = df_sem_nulo.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_out[outliers_index][['cliente.tempo_servico', 'conta.cobranca.mensal','conta.cobranca.Total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_out.loc[outliers_index, 'cliente.tempo_servico'] = np.ceil(\n",
    "    df_sem_out.loc[outliers_index, 'conta.cobranca.Total'] / df_sem_out.loc[outliers_index, 'conta.cobranca.mensal']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df_sem_out['cliente.tempo_servico'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percebemos que ainda temos alguns valores que sao outliers, portanto, vamos verificar quais sao\n",
    "df_sem_out[outliers_index][['cliente.tempo_servico', 'conta.cobranca.mensal','conta.cobranca.Total']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`mesmo apos realizarmos a atribuicao dos valores, percebemos que de fato nao podemos atribuir com exatidao e certeza os valores da coluna 'cliente.tempo_servico', logo, o mais aconselhavél é retirar essas informacoes do conjunto de dados que estamos preparando para um modelo de machine learning`**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Removendo Outliers**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_out[outliers_index]['cliente.tempo_servico']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df_sem_out['cliente.tempo_servico'].quantile(.25)\n",
    "Q3 = df_sem_out['cliente.tempo_servico'].quantile(.75)\n",
    "IQR = Q3 - Q1\n",
    "limite_inferior = Q1 - 1.5*IQR\n",
    "limite_superior = Q3 + 1.5*IQR\n",
    "\n",
    "outliers_index = (df_sem_out['cliente.tempo_servico'] < limite_inferior) | (df_sem_out['cliente.tempo_servico'] > limite_superior)\n",
    "outliers_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_out[outliers_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_out = df_sem_out[~outliers_index]\n",
    "df_sem_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df_sem_out['cliente.tempo_servico'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_out.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_out.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para saber mais: formas de identificar outliers\n",
    "\n",
    "Existem várias técnicas para detectar outliers em um conjunto de dados. Algumas das mais comuns são: Z-score, regra dos 3 sigmas e a análise de dispersão.\n",
    "\n",
    "**1) Z-score:**\n",
    "\n",
    "O z-score é uma medida estatística que indica a quantos múltiplos do desvio-padrão um dado está distante da média. Para detectar outliers utilizando essa medida, basta calcular o z-score de cada dado e verificar se ele está muito distante da média. Se o z-score for maior do que um determinado limite, podemos considerar esse dado como um outlier.\n",
    "\n",
    "O limite geralmente utilizado é de 3 desvios-padrões, ou seja, se o z-score de um dado for maior do que 3, podemos considerá-lo como um outlier.\n",
    "\n",
    "```python\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Dados de exemplo\n",
    "data = np.array([10, 20, 30, 40, 150, 50, 60, 70, 80, 90, 100, 350])\n",
    "\n",
    "# Cálculo do z-score\n",
    "z_scores = (data - np.mean(data)) / np.std(data)\n",
    "\n",
    "# Limite para considerar um dado como outlier\n",
    "limite = 3\n",
    "\n",
    "# Identificação dos outliers\n",
    "outliers = data[np.abs(z_scores) > limite]\n",
    "\n",
    "print(\"Outliers encontrados:\", outliers)\n",
    "```\n",
    "**2) Regra dos 3 sigmas:**\n",
    "\n",
    "A regra dos 3 sigmas é uma técnica que utiliza a distribuição normal para identificar outliers. Ela diz que cerca de 99,7% dos dados estarão dentro de 3 desvios padrão da média. Portanto, se um dado estiver a mais de 3 desvios padrão da média, podemos considerá-lo como um outlier.\n",
    "\n",
    "```python\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Criar um array com os dados\n",
    "dados = np.array([0, 10, 12, 13, 15, 16, 18, 20, 22, 25, 30, 35, 40, 50, 350])\n",
    "\n",
    "# Calcular a média e o desvio padrão do conjunto de dados\n",
    "media = np.mean(dados)\n",
    "desvio_padrao = np.std(dados)\n",
    "\n",
    "# Definir o limite superior e inferior para identificar os outliers\n",
    "limite_superior = media + (3 * desvio_padrao)\n",
    "limite_inferior = media - (3 * desvio_padrao)\n",
    "\n",
    "# Identificar os outliers no conjunto de dados\n",
    "outliers = dados[(dados > limite_superior) | (dados < limite_inferior)]\n",
    "\n",
    "print(\"Outliers:\", outliers)\n",
    "```\n",
    "**3) Análise de dispersão**\n",
    "\n",
    "A análise de dispersão é uma técnica que utiliza gráficos para identificar outliers. Um gráfico comumente utilizado é o boxplot que mostra a distribuição dos dados em quartis. Os outliers são identificados como pontos fora dos limites superior e inferior do boxplot.\n",
    "\n",
    "```python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Dados de exemplo\n",
    "data = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "\n",
    "# Criação do boxplot\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(data)\n",
    "\n",
    "# Identificação dos outliers\n",
    "outliers = data[(data < np.percentile(data, 25) - (1.5 * (np.percentile(data, 75) - np.percentile(data, 25)))) |\n",
    "                (data > np.percentile(data, 75) + (1.5 * (np.percentile(data, 75) - np.percentile(data, 25))))]\n",
    "\n",
    "print(\"Outliers encontrados:\", outliers)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Trabalhando com variáveis categóricas**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Variável Categórica**\n",
    "\n",
    "- Forma de agrupar informacoes em categorias distintas, portanto, não consigo atribuir números para ela.\n",
    "  Ex: Cor de olho: verde, castanho ou azul\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Substituindo Valores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a coluna id_cliente nao é interessante manter pensando no nosso modelo de machine learning, pois seria mais uma coluna para ele tentar relacionar. Nesse caso, como sao valores unicos, nao faz sentido manter.\n",
    "df_sem_id = df_sem_out.drop(columns='id_cliente', axis=1).copy()\n",
    "df_sem_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as colunas que estao com valores 0 ou 1, sao colunas que possuem variaveis categoricas binarias, ou seja, que possuem apenas duas categorias distintas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para poder substituir os valores e alterar para o padrao de 0 e 1, iremos fazer uma mapeamento das informacoes que queremos substituir\n",
    "\n",
    "mapeamento = {\n",
    "    'nao': 0,\n",
    "    'sim': 1,\n",
    "    'masculino': 0,\n",
    "    'feminino': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_sem_id.columns:\n",
    "    print(f'Coluna: {col}')\n",
    "    print(df_sem_id[col].unique())\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# portando com o codigo acima, conseguimos visualizar as colunas que sao do tipo binarias e vamos mapear atribuindo a uma variavel\n",
    "colunas = ['telefone.servico_telefone', 'Churn', 'cliente.parceiro', 'cliente.dependentes', 'conta.faturamente_eletronico', 'cliente.genero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_id[colunas] = df_sem_id[colunas].replace(mapeamento).astype(int)\n",
    "df_sem_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_sem_id.columns:\n",
    "    print(f'Coluna: {col}')\n",
    "    print(df_sem_id[col].unique())\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Para saber mais: o que são variáveis categóricas?**\n",
    "\n",
    "As **variáveis categóricas** são um tipo de variável usado em Ciência de Dados para representar dados que podem ser classificados em diferentes categorias ou grupos. Por exemplo, se uma pessoa cientista de dados estiver analisando o desempenho acadêmico de estudantes em uma escola, ela pode usar variáveis categóricas para classificar o desempenho dessas pessoas em diferentes grupos, como \"excelente\", \"bom\" ou \"regular\". Isso permite identificar padrões ou tendências no desempenho.\n",
    "\n",
    "Existem muitos exemplos de variáveis categóricas na Ciência de Dados. Algumas das mais comuns incluem a cor dos olhos, o tipo sanguíneo, a marca de um carro ou a escolaridade. Essas variáveis não possuem uma escala numérica e não podem ser medidas em termos de magnitude ou intensidade. Em vez disso, elas são usadas para classificar dados em diferentes grupos ou categorias.\n",
    "\n",
    "Dentre os tipos de variáveis, temos:\n",
    "\n",
    "**- Variáveis categóricas nominais**\n",
    "\n",
    "São aquelas que não possuem uma ordem ou hierarquia específica entre as categorias. Por exemplo, se uma pessoa cientista de dados estiver analisando a preferência musical de um grupo de pessoas, ela pode usar variáveis categóricas nominais para classificar as pessoas em diferentes grupos, como: \"rock\", \"jazz\" ou \"pop\".\n",
    "\n",
    "**- Variáveis categóricas ordinais**\n",
    "\n",
    "Possuem uma ordem específica entre as categorias. Por exemplo, se a pessoa cientista de dados estiver analisando a escolaridade de um grupo de pessoas, ela pode usar esse tipo de variável para classificar as pessoas em diferentes grupos, como: \"ensino fundamental completo\", \"ensino médio completo\" ou \"ensino superior completo\" e assim por diante.\n",
    "\n",
    "**- Variáveis categóricas binárias**\n",
    "\n",
    "São um tipo especial de variável categórica que possui apenas duas categorias possíveis, por exemplo: sim/não, verdadeiro/falso ou presente/ausente. As variáveis categóricas binárias são úteis porque permitem que cientistas de dados analisem a distribuição de dados em apenas duas categorias possíveis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Onde Hot Enconder (Dummy)**\n",
    "\n",
    "Com a **versão 2.0.0 do Pandas**, lançada em 03 de abril de 2023, houve uma mudança no valor padrão/default do parâmetro dtype do [método get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) . Ele passou de np.uint8 para bool.\n",
    "\n",
    "Mas o que isso implica nas saídas que obtemos? Isso significa que você vai obter True e False ao invés de 1 e 0, caso esteja usando a versão 2.0.0 ou superior do Pandas, como no exemplo abaixo:\n",
    "\n",
    "```python\n",
    "\n",
    "s = pd.Series(list('abca'))\n",
    "pd.get_dummies(s)Copiar código\n",
    "\n",
    "```\n",
    "**Saída**\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th></th>\n",
    "            <th>a</th>\n",
    "            <th>b</th>\n",
    "            <th>c</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>0</td>\n",
    "            <td>True</td>\n",
    "            <td>False</td>\n",
    "            <td>False</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>1</td>\n",
    "            <td>False</td>\n",
    "            <td>True</td>\n",
    "            <td>False</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>2</td>\n",
    "            <td>False</td>\n",
    "            <td>False</td>\n",
    "            <td>True</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>3</td>\n",
    "            <td>True</td>\n",
    "            <td>False</td>\n",
    "            <td>False</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "Essa mudança não tem implicações práticas para o propósito do projeto desse curso, que é preparar a base de dados para ser inserida em um modelo de machine learning, pois True e False são essencialmente equivalentes a 1 e 0, respectivamente. Portanto, ao criar variáveis dummies em Python, você pode usar True e False (sem precisar converter explicitamente para 1 e 0) e deixar as variáveis dummies com True e False sem problemas.\n",
    "\n",
    "Caso sua intenção seja obter exatamente o mesmo resultado mostrado instrutor, basta passar o valor int para o parâmetro dtype da seguinte forma:\n",
    "\n",
    "```python\n",
    "\n",
    "import pandas as pd\n",
    "s = pd.Series(list('abca'))\n",
    "pd.get_dummies(s, dtype=int)  # aqui inserir o valor para o dtypeCopiar código\n",
    "\n",
    "```\n",
    "**Saída**\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th></th>\n",
    "            <th>a</th>\n",
    "            <th>b</th>\n",
    "            <th>c</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>0</td>\n",
    "            <td>1</td>\n",
    "            <td>0</td>\n",
    "            <td>0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>1</td>\n",
    "            <td>0</td>\n",
    "            <td>1</td>\n",
    "            <td>0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>2</td>\n",
    "            <td>0</td>\n",
    "            <td>0</td>\n",
    "            <td>1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>3</td>\n",
    "            <td>1</td>\n",
    "            <td>0</td>\n",
    "            <td>0</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "Caso você queira conhecer mais do método, deixamos como sugestão de leitura complementar a documentação do método [get_dummies()](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(list('abca'))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(s, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_id.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(df_sem_id, dtype=int).copy()\n",
    "df_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Para saber mais: parâmetros do get_dummies()**\n",
    "\n",
    "O [método get_dummies()](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) da biblioteca Pandas é utilizado para transformar variáveis categóricas em variáveis binárias. Abaixo estão os parâmetros do método:\n",
    "\n",
    "1. `data`: **parâmetro obrigatório** que representa o conjunto de dados e contém as variáveis categóricas a serem transformadas em variáveis binárias.\n",
    "\n",
    "2. `prefix`: é um parâmetro opcional utilizado para adicionar um prefixo às colunas binárias geradas pelo método `get_dummies()`. Por exemplo, se você definir o prefixo como \"cat_\", as colunas binárias geradas terão nomes como \"cat_1\", \"cat_2\", etc.\n",
    "\n",
    "3. `prefix_sep`: parâmetro opcional utilizado para definir o separador entre o prefixo e o nome original da coluna categórica. O valor padrão é \"_\".\n",
    "\n",
    "4. `columns`: parâmetro opcional utilizado para selecionar as colunas específicas do conjunto de dados que devem ser transformadas em variáveis binárias. Se não for especificado, todas as colunas categóricas serão transformadas.\n",
    "\n",
    "5. `drop_first`: é um parâmetro opcional utilizado para remover a primeira coluna binária gerada pelo método `get_dummies()`. Isso é feito para evitar a multicolinearidade, que é uma situação em que duas ou mais variáveis independentes estão altamente correlacionadas entre si.\n",
    "\n",
    "6. `dtype`: parâmetro opcional utilizado para definir o tipo de dado das colunas binárias geradas pelo método `get_dummies()`. O valor padrão é \"uint8\".\n",
    "\n",
    "Abaixo está um exemplo de como podemos aplicar esses parâmetros:\n",
    "\n",
    "```python\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Criando um DataFrame de exemplo\n",
    "df = pd.DataFrame({'cor': ['vermelho', 'azul', 'verde', 'vermelho'],\n",
    "                   'tamanho': ['pequeno', 'médio', 'grande', 'médio'],\n",
    "                   'formato': ['quadrado', 'redondo', 'redondo', 'quadrado']})\n",
    "\n",
    "# Transformando as colunas categóricas em variáveis numéricas binárias\n",
    "df_dummies = pd.get_dummies(df, columns=['cor', 'tamanho'], prefix=['cor', 'tam'], prefix_sep='-', drop_first=True)\n",
    "\n",
    "# Exibindo o DataFrame resultante\n",
    "df_dummies\n",
    "```\n",
    "\n",
    "**Saída:**\n",
    "\n",
    "Neste exemplo, o parâmetro `data` é o DataFrame `df` que contém as colunas categóricas a serem transformadas. O parâmetro `columns` é uma lista que contém os nomes das colunas categóricas a serem transformadas em variáveis binárias. O parâmetro `prefix` é uma lista que contém os prefixos a serem adicionados às colunas binárias geradas. Aqui, estamos adicionando o prefixo \"cor_\" às colunas binárias geradas a partir da coluna \"cor\" e o prefixo \"tam_\" às colunas binárias geradas a partir da coluna \"tamanho\".\n",
    "\n",
    "Adicionamos também os parâmetros `prefix_sep='-'` para definir o separador entre o prefixo e o nome original da coluna categórica como um hífen (-). Também adicionamos o parâmetro `drop_first=True` para remover a primeira coluna binária gerada pelo método get_dummies(). Isso é feito para evitar a multicolinearidade, que é uma situação em que duas ou mais variáveis independentes estão altamente correlacionadas entre si.\n",
    "\n",
    "O resultado será um novo DataFrame chamado `df_dummies`, que contém as colunas originais do DataFrame `df`, bem como as novas colunas binárias geradas pelo método `get_dummies()` com um hífen (-) como separador de prefixo e a primeira coluna binária removida."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
